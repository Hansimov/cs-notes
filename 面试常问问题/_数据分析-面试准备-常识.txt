## HTTP vs HTTPS

* 十分钟搞懂 HTTP 和 HTTPS 协议？ - 知乎 
    * https：//zhuanlan.zhihu.com/p/72616216

* HTTP 和 HTTPS 协议，看一篇就够了_不一样的博客 - CSDN 博客 
    * https：//blog.csdn.net/xiaoming100001/article/details/81109617


HTTP 超文本传输协议，是一个基于请求与响应，无状态的，应用层的协议，常基于 TCP/IP 协议传输数据，互联网上应用最为广泛的一种网络协议，所有的 WWW 文件都必须遵守这个标准。设计 HTTP 的初衷是为了提供一种发布和接收 HTML 页面的方法。
HTTP 是一个基于 TCP/IP 通信协议来传递数据的协议，传输的数据类型为 HTML 文件、图片、查询结果等。
HTTP 协议一般用于 B/S 架构。浏览器作为 HTTP 客户端通过 URL 向 HTTP 服务端即 WEB 服务器发送所有请求。

特点：
1、客户端 / 服务端模式，请求 / 响应模式
2、简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有 GET、HEAD、POST。
3、灵活：HTTP 允许传输任意类型的数据对象。传输的类型由 Content-Type 加以标记。
4、无连接：限制每次连接只处理一个请求。服务器处理完请求，并收到客户的应答后，即断开连接，但是却不利于客户端与服务器保持会话连接，为了弥补这种不足，产生了两项记录 http 状态的技术，一个叫做 Cookie，一个叫做 Session。
5、无状态：无状态是指协议对于（客户端）事务处理没有记忆，后续处理需要前面的信息，则必须重传。
6、通信使用明文、请求和响应不会对通信方进行确认、无法保护数据的完整性


URI：Uniform Resource Identifier，统一资源标识符
URL：Uniform Resource Location，统一资源定位符

HTTP 使用统一资源标识符 URI 来传输数据和建立连接。

URI 是用来标示一个具体的资源的，我们可以通过 URI 知道一个资源是什么。
URL 则是用来定位具体的资源的，标示了一个具体的资源位置。互联网上的每个文件都有一个唯一的 URL。

HTTP 报文
1、请求行：包括请求方法、URL、协议 / 版本
2、请求头（Request Header）
3、请求正文

响应报文构成
1、状态行
2、响应头
3、响应正文

常见请求方法
1、GET：请求指定的页面信息，并返回实体主体。
2、POST：向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和 / 或已有资源的修改。
3、HEAD：类似于 get 请求，只不过返回的响应中没有具体的内容，用于获取报头
4、PUT：从客户端向服务器传送的数据取代指定的文档的内容。
5、DELETE：请求服务器删除指定的页面。

post 和 get 的区别：
1、都包含请求头请求行，post 多了请求 body。
2、get 多用来查询，请求参数放在 url 中，不会对服务器上的内容产生作用。post 用来提交，如把账号密码放入 body 中。
3、GET 是直接添加到 URL 后面的，直接就可以在 URL 中看到内容，而 POST 是放在报文内部的，用户无法直接看到。
4、GET 提交的数据长度是有限制的，因为 URL 长度有限制，具体的长度限制视浏览器而定。而 POST 没有。


响应状态码
访问一个网页时，浏览器会向 web 服务器发出请求。此网页所在的服务器会返回一个包含 HTTP 状态码的信息头用以响应浏览器的请求。

状态码分类
1XX- 信息型，服务器收到请求，需要请求者继续操作。
2XX- 成功型，请求成功收到，理解并处理。
3XX - 重定向，需要进一步的操作以完成请求。
4XX - 客户端错误，请求包含语法错误或无法完成请求。
5XX - 服务器错误，服务器在处理请求的过程中发生了错误。

常见状态码：
200 OK - 客户端请求成功
301 - 资源（网页等）被永久转移到其它 URL
302 - 临时跳转
400 Bad Request - 客户端请求有语法错误，不能被服务器所理解
401 Unauthorized - 请求未经授权，这个状态代码必须和 WWW-Authenticate 报头域一起使用
404 - 请求资源不存在，可能是输入了错误的 URL
500 - 服务器内部发生了不可预期的错误
503 Server Unavailable - 服务器当前不能处理客户端的请求，一段时间后可能恢复正常。

为什么要用 https？
实际使用中，绝大多数的网站现在都采用的是 https 协议。
HTTP 的账号密码都是明文传输，这样客户端发出的请求很容易被不法分子截取利用，因此，HTTP 协议不适合传输一些敏感信息，使用 http 协议传输隐私信息非常不安全。

一般 http 中存在如下问题：
1、请求信息明文传输，容易被窃听截取
2、数据的完整性未校验，容易被篡改
3、没有验证对方身份，存在冒充危险

为了解决上述 HTTP 存在的问题，就用到了 HTTPS。
HTTPS 协议（HyperText Transfer Protocol over Secure Socket Layer）：一般理解为 HTTP + SSL/TLS，通过 SSL 证书来验证服务器的身份，并为浏览器和服务器之间的通信进行加密。
HTTPS 是身披 SSL 外壳的 HTTP，主要目的是提供对网站服务器的身份认证，同时保护交换数据的隐私与完整性。

HTTPS 有如下特点：
1、内容加密：采用混合加密技术，中间者无法直接查看明文内容
2、验证身份：通过证书认证客户端访问的是自己的服务器
    - 收方能够证实发送方的真实身份
3、保护数据完整性：防止传输的内容被中间人冒充或者篡改
    - 发送方事后不能否认所发送过的报文
    - 收方或非法者不能伪造、篡改报文

混合加密：结合非对称加密和对称加密技术。客户端使用对称加密生成密钥对传输数据进行加密，然后使用非对称加密的公钥再对秘钥进行加密，所以网络上传输的数据是被秘钥加密的密文和用公钥加密后的秘密秘钥，因此即使被黑客截取，由于没有私钥，无法获取到加密明文的秘钥，便无法获取到明文数据。

数字摘要：通过单向 hash 函数对原文进行哈希，将需加密的明文 “摘要” 成一串固定长度（如 128 bit）的密文，不同的明文摘要成的密文其结果总是不相同，同样的明文其摘要必定一致，并且即使知道了摘要也不能反推出明文。

数字签名技术：数字签名建立在公钥加密体制基础上，是公钥加密技术的另一类应用。它把公钥加密技术和数字摘要结合起来，形成了实用的数字签名技术。


那么 SSL 又是什么？
SSL（Secure Socket Layer，安全套接字层）：SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。
TLS（Transport Layer Security，传输层安全）：是传输层加密协议，其前身是 SSL，目前使用最广泛的是 TLS 1.1、TLS 1.2。


浏览器在使用 HTTPS 传输数据的流程是什么？
1、首先客户端通过 URL 访问服务器建立 SSL 连接。
2、服务端收到客户端请求后，会将网站支持的证书信息（证书中包含公钥）传送一份给客户端。
3、客户端的服务器开始协商 SSL 连接的安全等级，也就是信息加密的等级。
4、客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。
5、服务器利用自己的私钥解密出会话密钥。
6、服务器利用会话密钥加密与客户端之间的通信。

HTTPS 的缺点
1、HTTPS 协议多次握手，导致页面的加载时间延长近 50%；
2、HTTPS 连接缓存不如 HTTP 高效，会增加数据开销和功耗；
3、申请 SSL 证书需要钱，功能越强大的证书费用越高。
4、SSL 涉及到的安全算法会消耗 CPU 资源，对服务器资源消耗较大。


总结 HTTPS 和 HTTP 的区别
1、HTTPS 是 HTTP 协议的安全版本，HTTP 协议的数据传输是明文的，是不安全的，HTTPS 使用了 SSL/TLS 协议进行了加密处理。
2、http 和 https 使用连接方式不同，默认端口也不一样，http 是 80，https 是 443。


## TCP 三次握手和四次挥手

* 两张动图 - 彻底明白 TCP 的三次握手与四次挥手_qzcsu 的博客 - CSDN 博客 
    * https：//blog.csdn.net/qzcsu/article/details/72861891

* TCP 协议 · 笔试面试知识整理 
    * https：//hit-alibaba.github.io/interview/basic/network/TCP.html


TCP 把连接作为最基本的对象，每一条 TCP 连接都有两个端点，这种断点我们叫作套接字（socket），它的定义为端口号拼接到 IP 地址即构成了套接字。
例如，若 IP 地址为 192.3.4.16 而端口号为 80，那么得到的套接字为 192.3.4.16：80。

TCP 的特性
- TCP 提供一种面向连接的、可靠的字节流服务
- 在一个 TCP 连接中，仅有两方进行彼此通信。广播和多播不能用于 TCP
- TCP 使用校验和，确认和重传机制来保证可靠传输
- TCP 给数据分节进行排序，并使用累积确认保证数据的顺序不变和非重复
- TCP 使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制

注意：TCP 并不能保证数据一定会被对方接收到，因为这是不可能的。TCP 能够做到的是，如果有可能，就把数据递送到接收方，否则就（通过放弃重传并且中断连接这一手段）通知用户。因此准确说 TCP 也不是 100% 可靠的协议，它所能提供的是数据的可靠递送或故障的可靠通知。

TCP 报文首部
1、源端口和目的端口，各占 2 个字节，分别写入源端口和目的端口；
2、序号，占 4 个字节，TCP 连接中传送的字节流中的每个字节都按顺序编号。例如，一段报文的序号字段值是 301 ，而携带的数据共有 100 字段，显然下一个报文段（如果还有的话）的数据序号应该从 401 开始；
3、确认号，占 4 个字节，是期望收到对方下一个报文的第一个数据字节的序号。例如，B 收到了 A 发送过来的报文，其序列号字段是 501，而数据长度是 200 字节，这表明 B 正确的收到了 A 发送的到序号 700 为止的数据。因此，B 期望收到 A 的下一个数据序号是 701，于是 B 在发送给 A 的确认报文段中把确认号置为 701；
4、数据偏移，占 4 位，它指出 TCP 报文的数据距离 TCP 报文段的起始处有多远；
5、保留，占 6 位，保留今后使用，但目前应都为 0；
6、紧急 URG，当 URG=1，表明紧急指针字段有效。告诉系统此报文段中有紧急数据；
7、确认 ACK，仅当 ACK=1 时，确认号字段才有效。TCP 规定，在连接建立后所有报文的传输都必须把 ACK 置 1；
8、推送 PSH，当两个应用进程进行交互式通信时，有时在一端的应用进程希望在键入一个命令后立即就能收到对方的响应，这时候就将 PSH=1；
9、复位 RST，当 RST=1，表明 TCP 连接中出现严重差错，必须释放连接，然后再重新建立连接；
10、同步 SYN，在连接建立时用来同步序号。当 SYN=1，ACK=0，表明是连接请求报文，若同意连接，则响应报文中应该使 SYN=1，ACK=1；
11、终止 FIN，用来释放连接。当 FIN=1，表明此报文的发送方的数据已经发送完毕，并且要求释放；
12、窗口，占 2 字节，指的是通知接收方，发送本报文你需要有多大的空间来接受；
13、检验和，占 2 字节，校验首部和数据这两部分；
14、紧急指针，占 2 字节，指出本报文段中的紧急数据的字节数；
15、选项，长度可变，定义一些其他的可选的参数。


TCP 的三次握手
所谓三次握手（Three-way Handshake），是指建立一个 TCP 连接时，需要客户端和服务器总共发送 3 个包。
三次握手的目的是连接服务器指定端口，建立 TCP 连接，并同步连接双方的序列号和确认号，交换 TCP 窗口大小信息。在 socket 编程中，客户端执行 connect（） 时。将触发三次握手。

1、第一次握手（SYN=1， seq=x）：
客户端发送一个 TCP 的 SYN 标志位置 1 的包，指明客户端打算连接的服务器的端口，以及初始序号 X，保存在包头的序列号（Sequence Number）字段里。
发送完毕后，客户端进入 SYN_SENT 状态。

2、第二次握手（SYN=1， ACK=1， seq=y， ACKnum=x+1）：
服务器发回确认包（ACK）应答。即 SYN 标志位和 ACK 标志位均为 1。服务器端选择自己 ISN 序列号，放到 Seq 域里，同时将确认序号（Acknowledgement Number）设置为客户的 ISN 加 1，即 X+1。
发送完毕后，服务器端进入 SYN_RCVD 状态。

3、第三次握手（ACK=1，ACKnum=y+1）
客户端再次发送确认包（ACK），SYN 标志位为 0，ACK 标志位为 1，并且把服务器发来 ACK 的序号字段 + 1，放在确定字段中发送给对方，并且在数据段放写 ISN 的 + 1
发送完毕后，客户端进入 ESTABLISHED 状态。
当服务器端接收到这个包时，也进入 ESTABLISHED 状态，TCP 握手结束。

TCP 连接的建立（三次握手）
0、最开始的时候客户端和服务器都是处于 CLOSED 状态。主动打开连接的为客户端，被动打开连接的是服务器。
1、TCP 服务器进程先创建传输控制块 TCB，时刻准备接受客户进程的连接请求，此时服务器就进入了 LISTEN（监听）状态；
2、TCP 客户进程也是先创建传输控制块 TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位 SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP 客户端进程进入了 SYN-SENT（同步已发送状态）状态。TCP 规定，SYN 报文段（SYN=1 的报文段）不能携带数据，但需要消耗掉一个序号。
3、TCP 服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是 ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP 服务器进程进入了 SYN-RCVD（同步收到）状态。这个报文也不能携带数据，但是同样要消耗一个序号。
4、TCP 客户进程收到确认后，还要向服务器给出确认。确认报文的 ACK=1，ack=y+1，自己的序列号 seq=x+1，此时，TCP 连接建立，客户端进入 ESTABLISHED（已建立连接）状态。TCP 规定，ACK 报文段可以携带数据，但是如果不携带数据则不消耗序号。
5、当服务器收到客户端的确认后也进入 ESTABLISHED 状态，此后双方就可以开始通信了。

为什么 TCP 客户端最后还要发送一次确认呢？
一句话，主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。

如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于 TCP 的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。
此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。

如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。


TCP 四次挥手
TCP 的连接的拆除需要发送四个包，因此称为四次挥手（Four-way handshake），也叫做改进的三次握手。客户端或服务器均可主动发起挥手动作，在 socket 编程中，任何一方执行 close（） 操作即可产生挥手操作。

1、第一次挥手（FIN=1，seq=x）
假设客户端想要关闭连接，客户端发送一个 FIN 标志位置为 1 的包，表示自己已经没有数据可以发送了，但是仍然可以接受数据。
发送完毕后，客户端进入 FIN_WAIT_1 状态。

2、第二次挥手（ACK=1，ACKnum=x+1）
服务器端确认客户端的 FIN 包，发送一个确认包，表明自己接受到了客户端关闭连接的请求，但还没有准备好关闭连接。
发送完毕后，服务器端进入 CLOSE_WAIT 状态，客户端接收到这个确认包之后，进入 FIN_WAIT_2 状态，等待服务器端关闭连接。

3、第三次挥手（FIN=1，seq=y）（信号有问题）
服务器端准备好关闭连接时，向客户端发送结束连接请求，FIN 置为 1。
发送完毕后，服务器端进入 LAST_ACK 状态，等待来自客户端的最后一个 ACK。

4、第四次挥手（ACK=1，ACKnum=y+1）（信号有问题）
客户端接收到来自服务器端的关闭请求，发送一个确认包，并进入 TIME_WAIT 状态，等待可能出现的要求重传的 ACK 包。
服务器端接收到这个确认包之后，关闭连接，进入 CLOSED 状态。
客户端等待了某个固定时间（两个最大段生命周期，2 MSL，2 Maximum Segment Lifetime）之后，没有收到服务器端的 ACK ，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入 CLOSED 状态。

TCP 连接的释放（四次挥手）
数据传输完毕后，双方都可释放连接。最开始的时候，客户端和服务器都是处于 ESTABLISHED 状态，然后客户端主动关闭，服务器被动关闭。

1、客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为 seq=u（等于前面已经传送过来的数据的最后一个字节的序号加 1），此时，客户端进入 FIN-WAIT-1（终止等待 1）状态。 TCP 规定，FIN 报文段即使不携带数据，也要消耗一个序号。
2、服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号 seq=v，此时，服务端就进入了 CLOSE-WAIT（关闭等待）状态。TCP 服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个 CLOSE-WAIT 状态持续的时间。
3、客户端收到服务器的确认请求后，此时，客户端就进入 FIN-WAIT-2（终止等待 2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
4、服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为 seq=w，此时，服务器就进入了 LAST-ACK（最后确认）状态，等待客户端的确认。
5、客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是 seq=u+1，此时，客户端就进入了 TIME-WAIT（时间等待）状态。注意此时 TCP 连接还没有释放，必须经过 2*MSL（最长报文段寿命）的时间后，当客户端撤销相应的 TCB 后，才进入 CLOSED 状态。
6、服务器只要收到了客户端发出的确认，立即进入 CLOSED 状态。同样，撤销 TCB 后，就结束了这次的 TCP 连接。可以看到，服务器结束 TCP 连接的时间要比客户端早一些。



为什么客户端最后还要等待 2 MSL？
MSL（Maximum Segment Lifetime），TCP 允许不同的实现可以设置不同的 MSL 值。
第一，保证客户端发送的最后一个 ACK 报文能够到达服务器，因为这个 ACK 报文可能丢失，站在服务器的角度看来，我已经发送了 FIN+ACK 报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个 2MSL 时间段内收到这个重传的报文，接着给出回应报文，并且会重启 2MSL 计时器。
第二，防止类似与 “三次握手” 中提到了的 “已经失效的连接请求报文段” 出现在本连接中。客户端发送完最后一个确认报文后，在这个 2MSL 时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。

为什么建立连接是三次握手，关闭连接确是四次挥手呢？
建立连接的时候， 服务器在 LISTEN 状态下，收到建立连接请求的 SYN 报文后，把 ACK 和 SYN 放在一个报文里发送给客户端。
而关闭连接时，服务器收到对方的 FIN 报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送 FIN 报文给对方来表示同意现在关闭连接，因此，己方 ACK 和 FIN 一般都会分开发送，从而导致多了一次。


如果已经建立了连接，但是客户端突然出现故障了怎么办？
TCP 还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为 2 小时，若 2 小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔 75 秒发送一次。若一连发送 10 个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

TCP KeepAlive
TCP 的连接，实际上是一种纯软件层面的概念，在物理层面并没有 “连接” 这种概念。TCP 通信双方建立交互的连接，但是并不是一直存在数据交互，有些连接会在数据交互完毕后，主动释放连接，而有些不会。在长时间无数据交互的时间段内，交互双方都有可能出现掉电、死机、异常重启等各种意外，当这些意外发生之后，这些 TCP 连接并未来得及正常释放，在软件层面上，连接的另一方并不知道对端的情况，它会一直维护这个连接，长时间的积累会导致非常多的半打开连接，造成端系统资源的消耗和浪费，为了解决这个问题，在传输层可以利用 TCP 的 KeepAlive 机制实现来实现。主流的操作系统基本都在内核里支持了这个特性。

TCP KeepAlive 的基本原理是，隔一段时间给连接对端发送一个探测包，如果收到对方回应的 ACK，则认为连接还是存活的，在超过一定重试次数之后还是没有收到对方的回应，则丢弃该 TCP 连接。

TCP-Keepalive-HOWTO 有对 TCP KeepAlive 特性的详细介绍。
TCP KeepAlive 的局限：
首先 TCP KeepAlive 监测的方式是发送一个 probe 包，会给网络带来额外的流量，另外 TCP KeepAlive 只能在内核层级监测连接的存活与否，而连接的存活不一定代表服务的可用。例如当一个服务器 CPU 进程服务器占用达到 100%，已经卡死不能响应请求了，此时 TCP KeepAlive 依然会认为连接是存活的。因此 TCP KeepAlive 对于应用层程序的价值是相对较小的，需要做连接保活的应用层程序，例如 QQ，往往会在应用层实现自己的心跳功能。

## OSI 七层模型 和 TCP/IP 四层模型
* 一文读懂 OSI 七层模型与 TCP/IP 四层的区别 / 联系_Machine Learning with Turing's Cat-CSDN 博客 
    * https：//blog.csdn.net/qq_39521554/article/details/79894501

## TCP vs UDP

* TCP 和 UDP 的区别 - 知乎 
    * https://zhuanlan.zhihu.com/p/24860273
* TCP 和 UDP 的最完整的区别_Li_Ning_的博客 - CSDN 博客 
    * https://blog.csdn.net/Li_Ning_/article/details/52117463

个人总结（TCP vs UDP）：
1、连接 vs 无连接
2、可靠（不错、不少、不重、不乱） vs 不保证可靠
3、流 vs 数据包（无拥塞控制）
4、点到点 vs 多对多
5、开销大（20 字节） vs 开销小（8 字节）
6、复杂 vs 简单

TCP 与 UDP 的区别：
1、基于连接与无连接；
2、对系统资源的要求（TCP 较多，UDP 少）；
3、UDP 程序结构较简单；
4、流模式与数据报模式；
5、TCP 保证数据正确性，UDP 可能丢包；
6、TCP 保证数据顺序，UDP 不保证。

1、TCP 面向连接（如打电话要先拨号建立连接）；UDP 是无连接的，即发送数据之前不需要建立连接
2、TCP 提供可靠的服务。也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达; UDP 尽最大努力交付，即不保证可靠交付
3、TCP 面向字节流，实际上是 TCP 把数据看成一连串无结构的字节流； UDP 是面向报文的
  UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 IP 电话，实时视频会议等）
4、每一条 TCP 连接只能是点到点的; UDP 支持一对一，一对多，多对一和多对多的交互通信
5、TCP 首部开销 20 字节; UDP 的首部开销小，只有 8 个字节
6、TCP 的逻辑通信信道是全双工的可靠信道，UDP 则是不可靠信道


IP 层在网络层，可以实现两个主机之间的通信。但是这并不具体，因为真正进行通信的实体是在主机中的进程，是一个主机中的一个进程与另外一个主机中的一个进程在交换数据。IP 协议虽然能把数据报文送到目的主机，但是并没有交付给主机的具体应用进程。而端到端的通信才应该是应用进程之间的通信。
UDP，在传送数据前不需要先建立连接，远地的主机在收到 UDP 报文后也不需要给出任何确认。虽然 UDP 不提供可靠交付，但是正是因为这样，省去和很多的开销，使得它的速度比较快，比如一些对实时性要求较高的服务，就常常使用的是 UDP。对应的应用层的协议主要有 DNS，TFTP，DHCP，SNMP，NFS 等。
TCP，提供面向连接的服务，在传送数据之前必须先建立连接，数据传送完成后要释放连接。因此 TCP 是一种可靠的的运输服务，但是正因为这样，不可避免的增加了许多的开销，比如确认，流量控制等。对应的应用层的协议主要有 SMTP，TELNET，HTTP，FTP 等。

TCP/IP 协议是一个协议簇。里面包括很多协议的，UDP 只是其中的一个， 之所以命名为 TCP/IP 协议，因为 TCP、IP 协议是两个很重要的协议，就用他两命名了。

TCP/IP 协议集包括：应用层、传输层、网络层、网络访问层。

应用层包括:
1、超文本传输协议（HTTP）: 万维网的基本协议；
2、文件传输（TFTP 简单文件传输协议）；
3、远程登录（Telnet），提供远程访问其它主机功能, 它允许用户登录 internet 主机，并在这台主机上执行命令；
4、网络管理（SNMP 简单网络管理协议），该协议提供了监控网络设备的方法， 以及配置管理, 统计信息收集, 性能管理及安全管理等；
5、域名系统（DNS），该系统用于在 internet 中将域名及其公共广播的网络节点转换成 IP 地址。

其次网络层包括:
1、Internet 协议（IP）；
2、Internet 控制信息协议（ICMP）；
3、地址解析协议（ARP）；
4、反向地址解析协议（RARP）。

最后说网络访问层:
网络访问层又称作主机到网络层（host-to-network），网络访问层的功能包括 IP 地址与物理地址硬件的映射， 以及将 IP 封装成帧. 基于不同硬件类型的网络接口，网络访问层定义了和物理介质的连接. 当然我这里说得不够完善，TCP/IP 协议本来就是一门学问，每一个分支都是一个很复杂的流程， 但我相信每位学习软件开发的同学都有必要去仔细了解一番。

TCP 建立连接要进行 3 次握手，而断开连接要进行 4 次。
* 详见 TCP 三次握手和四次挥手

UDP（User Datagram Protocol，用户数据报协议）
包头结构
    源端口 16 位
    目的端口 16 位
    长度 16 位
    校验和 16 位

1、UDP 是一个非连接的协议，传输数据之前源端和终端不建立连接。
当它想传送时就简单地去抓取来自应用程序的数据，并尽可能快地把它扔到网络上。 在发送端，UDP 传送数据的速度仅仅是受应用程序生成数据的速度、 计算机的能力和传输带宽的限制； 在接收端，UDP 把每个消息段放在队列中，应用程序每次从队列中读一个消息段。
2、 由于传输数据不建立连接，因此也就不需要维护连接状态，包括收发状态等， 因此一台服务机可同时向多个客户机传输相同的消息。
3、UDP 信息包的标题很短，只有 8 个字节，相对于 TCP 的 20 个字节信息包的额外开销很小。
4、吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的速率、传输带宽、 源端和终端主机性能的限制。
5、UDP 使用尽最大努力交付，即不保证可靠交付， 因此主机不需要维持复杂的链接状态表（这里面有许多参数）。
6、UDP 是面向报文的。发送方的 UDP 对应用程序交下来的报文， 在添加首部后就向下交付给 IP 层。既不拆分，也不合并，而是保留这些报文的边界， 因此，应用程序需要选择合适的报文大小。


我们经常使用 “ping” 命令来测试两台主机之间 TCP/IP 通信是否正常， 其实 “ping” 命令的原理就是向对方主机发送 UDP 数据包，然后对方主机确认收到数据包， 如果数据包是否到达的消息及时反馈回来，那么网络就是通的。
ping 命令是用来探测主机到主机之间是否可通信，如果不能 ping 到某台主机，表明不能和这台主机建立连接。ping 命令是使用 IP 和网络控制信息协议 (ICMP)，因而没有涉及到任何传输协议 (UDP/TCP) 和应用程序。它发送 icmp 回送请求消息给目的主机。
ICMP 协议规定：目的主机必须返回 ICMP 回送应答消息给源主机。如果源主机在一定时间内收到应答，则认为主机可达。



## 进程 vs 线程

* 《现代操作系统》 第 2 章

* 操作系统 - 小土刀的面试刷题笔记 
    * https：//wdxtub.com/interview/14520847747820.html

* 进程和线程的区别是什么？__牛客网 
    * https：//www.nowcoder.com/questionTerminal/234895a70e0b40e19db7f3fbaabc5fa3

* 面试总结，多进程和多线程的区别_CSDN-CSDN 博客 
    * https：//blog.csdn.net/linraise/article/details/12979473

一个进程就是一个正在执行程序的实例。
在传统操作系统中，每个进程有一个地址空间和一个控制线程。
进程是资源分配的最小单位，线程是 CPU 调度的最小单位

进程和线程的区别：
1、进程是运行中的程序，线程是进程的内部的一个执行序列
2、进程是资源分配的单元，线程是执行的单元
3、进程间切换代价大，线程间切换代价小
4、进程拥有资源多，线程拥有资源少
5、多个线程共享进程的资源

进程和线程的区别：
a、地址空间和其它资源：进程间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见。
b、通信：进程间通信 IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。
c、调度和切换：线程上下文切换比进程上下文切换要快得多。
d、在多线程 OS 中，进程不是一个可执行的实体。

从概念上：
- 进程：一个程序对一个数据集的动态执行过程，是分配资源的基本单位。
- 线程：一个进程内的基本调度单位。线程的划分尺度小于进程，一个进程包含一个或者更多的线程。
从执行过程中来看：
- 进程：拥有独立的内存单元，而多个线程共享内存，从而提高了应用程序的运行效率。
- 线程：每一个独立的线程，都有一个程序运行的入口、顺序执行序列、和程序的出口。但是线程不能够独立的执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。
从逻辑角度来看（重要区别）：
- 多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但是，操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理及资源分配。

个人总结：
1、进程是正在运行的程序，而线程则是进程中的一个执行序列。
2、进程和线程的核心区别在于地址空间和资源。进程是资源分配的单元，线程是执行的单元。
3、不同进程拥有独立的地址空间和资源，而同一进程中的线程则共享地址空间和进程中的资源。
4、进程拥有的资源多，线程拥有的少；进程的上下文切换代价大，线程的代价小。

协程，又称微线程，纤程。英文名 Coroutine。

协程可以理解为用户级线程，协程和线程的区别是：
线程是抢占式的调度，而协程是协同式的调度，协程避免了无意义的调度，由此可以提高性能，但也因此，程序员必须自己承担调度的责任，同时，协程也失去了标准线程使用多 CPU 的能力。

## 多进程 vs 多线程

* 多进程和多线程的概念 - fengMisaka - 博客园 
    * https：//www.cnblogs.com/linuxAndMcu/p/11064916.html

* 一文看懂 Python 多进程与多线程编程（工作学习面试必读） - 知乎 
    * https：//zhuanlan.zhihu.com/p/46368084

多线程是什么？
进程可以简单的理解为一个可以独立运行的程序单位，它是线程的集合，进程就是有一个或多个线程构成的。而线程是进程中的实际运行单位，是操作系统进行运算调度的最小单位。可理解为线程是进程中的一个最小运行单元。
那么多线程就很容易理解：多线程就是指一个进程中同时有多个线程正在执行。

为什么要使用多线程？
- 在一个程序中，有很多的操作是非常耗时的，如数据库读写操作、IO 操作等，如果使用单线程，那么程序就必须等待这些操作执行完成之后才能执行其他操作。使用多线程，可以在将耗时任务放在后台继续执行的同时，同时执行其他操作。
- 可以提高程序的效率。
- 在一些等待的任务上，如用户输入，文件读取等，多线程就非常有用了。

多线程的缺点：
- 使用太多线程，是很耗系统资源，因为线程需要开辟内存。更多线程需要更多内存。
- 影响系统性能，因为操作系统需要在线程之间来回切换。
- 需要考虑线程操作对程序的影响，如线程挂起，中止等操作对程序的影响。
- 线程使用不当会发生很多问题。

总结：多线程是异步的，但这不代表多线程真的是几个线程是在同时进行，实际上是系统不断地在各个线程之间来回的切换（因为系统切换的速度非常的快，所以给我们在同时运行的错觉）。


多进程是什么？
进程是程序在计算机上的一次执行活动。当你运行一个程序，你就启动了一个进程。凡是用于完成操作系统的各种功能的进程就是系统进程，而所有由你启动的进程都是用户进程。
同理，多进程就是指计算机同时执行多个进程，一般是同时运行多个软件。


多线程与多进程，选择谁？

知乎有一个通俗的比方。
- 单进程单线程：一个人在一个桌子上吃菜。
- 单进程多线程：多个人在同一个桌子上一起吃菜。
- 多进程单线程：多个人每个人在自己的桌子上吃菜。

多线程的问题是，资源共享会发生冲突争抢。

1、对于 Windows 系统来说，【开桌子】的开销很大，因此 Windows 鼓励大家在一个桌子上吃菜。因此 Windows 多线程学习重点是要大量面对资源争抢与同步方面的问题。
也就是说，Windows 鼓励多线程，但是要解决资源抢夺和同步问题。
2、对于 Linux 系统来说，【开桌子】的开销很小，因此 Linux 鼓励大家尽量每个人都开自己的桌子吃菜。这带来新的问题是：坐在两张不
同的桌子上，说话不方便。因此，Linux 下的学习重点大家要学习进程间通信的方法。
也就是说，Linux 鼓励多进程，但是要解决进程间通信的问题。

开销这里主要指的是时间开销。
可以做个实验：创建一个进程，在进程中往内存写若干数据，然后读出该数据，然后退出。此过程重复 1000 次，相当于创建 / 销毁进程 1000 次。在我机器上的测试结果是：
- Ubuntu ：耗时 0.8 秒
- Windows 7：耗时 79.8 秒。
两者开销大约相差一百倍。

这意味着，在 Windows 中，进程创建的开销不容忽视。换句话说就是，Windows 编程中不建议你创建进程，如果你的程序架构需要大量创建进程，那么最好是切换到 Linux 系统。

大量创建进程的典型例子有两个，一个是 gnu autotools 工具链，用于编译很多开源代码的，他们在 Windows 下编译速度会很慢，因此软件开发人员最好是避免使用 Windows。另一个是服务器，某些服务器框架依靠大量创建进程来干活，甚至是对每个用户请求就创建一个进程，这些服务器在 Windows 下运行的效率就会很差。这 "可能' 也是放眼全世界范围，Linux 服务器远远多于 Windows 服务器的原因。

如果你是写服务器端应用的，其实在现在的网络服务模型下，开新进程的开销是可以忽略不计的，因为现在一般流行的是按照 CPU 核心数量开进程或者线程，开完之后在数量上一直保持，进程与线程内部使用协程或者异步通信来处理多个并发连接，因而开进程与开线程的开销可以忽略了。

另外一种新的开销被提上日程：核心切换开销。现代的体系，一般 CPU 会有多个核心，而多个核心可以同时运行多个不同的线程或者进程。当每个 CPU 核心运行一个进程的时候，由于每个进程的资源都独立，所以 CPU 核心之间切换的时候无需考虑上下文。
当每个 CPU 核心运行一个线程的时候，由于每个线程需要共享资源，所以这些资源必须从 CPU 的一个核心被复制到另外一个核心，才能继续运算，这占用了额外的开销。换句话说，在 CPU 为多核的情况下，多线程在性能上不如多进程。
因而，当前面向多核的服务器端编程中，需要习惯多进程而非多线程。


由于 GIL 的存在，很多人认为 Python 多进程编程更快，针对多核 CPU，理论上来说也是采用多进程更能有效利用资源。网上很多人已做过比较，我直接告诉你结论吧。

- 对 CPU 密集型代码（比如循环计算）：多进程效率更高
- 对 IO 密集型代码（比如文件操作，网络爬虫）：多线程效率更高。

为什么是这样呢？其实也不难理解。对于 IO 密集型操作，大部分消耗时间其实是等待时间，在等待时间中 CPU 是不需要工作的，那你在此期间提供双 CPU 资源也是利用不上的，相反对于 CPU 密集型代码，2 个 CPU 干活肯定比一个 CPU 快很多。那么为什么多线程会对 IO 密集型代码有用呢？这时因为 python 碰到等待会释放 GIL 供新的线程使用，实现了线程间的切换。

并行、并发、高并发等概念
并行：多个 CPU 实例或多台机器同时执行一段处理逻辑，是真正的同时。
并发：通过 CPU 调度算法，让用户看上去同时执行，实际上 CPU 操作层面不是真正的同时。

并发时如果操作了公用资源，可能产生线程安全问题。
- 线程安全：多个线程操作公用资源，有可能产生安全问题。
- 高并发：高并发指的是是一种系统运行过程中遇到的一种 “短时间内遇到大量操作请求” 的情况，主要发生在 web 系统集中大量访问或者 socket 端口集中性收到大量请求（例如： 12306 的抢票情况；天猫双十一活动）。
该情况的发生会导致系统在这段时间内执行大量操作，例如对资源的请求，数据库的操作等。如果高并发处理不好，不仅仅降低了用户的体验度（请求响应时间过长），同时可能导致系统宕机，严重的甚至导致 OOM 异常，系统停止工作等。如果要想系统能够适应高并发状态，则需要从各个方面进行系统优化，包括，硬件、网络、系统架构、开发语言的选取、数据结构的运用、算法优化、数据库优化……。

多线程与高并发的联系
多线程只是在同步或异步角度上解决高并发问题的其中的一个方法手段，是在同一时刻利用计算机闲置资源的一种方式
多线程在高并发问题中的作用就是充分利用计算机资源，使计算机的资源在每一时刻都能达到最大的利用率，不至于浪费计算机资源使其闲置。


## 进程间通信 vs 线程间通信

* 进程间通信的方式——信号、管道、消息队列、共享内存 - 0giant - 博客园 
    * https：//www.cnblogs.com/luo77/p/5816326.html

* 面试 / 笔试第二弹 —— 操作系统面试问题集锦_Rico's Blogs-CSDN 博客 
    * https：//blog.csdn.net/justloveyou_/article/details/78304294

* 进程间通信 IPC （InterProcess Communication） - 简书 
    * https：//www.jianshu.com/p/c1015f5ffa74

* 进程间 8 种通信方式详解_在努力！-CSDN 博客 
    * https：//blog.csdn.net/violet_echo_0908/article/details/51201278


进程间通信的方式——信号、管道、消息队列、共享内存

多进程：
首先，先来讲一下 fork 之后，发生了什么事情。
> 由 fork 创建的新进程被称为子进程（child process）。该函数被调用一次，但返回两次。两次返回的区别是子进程的返回值是 0，而父进程的返回值则是新进程（子进程）的进程 id。将子进程 id 返回给父进程的理由是：因为一个进程的子进程可以多于一个，没有一个函数使一个进程可以获得其所有子进程的进程 id。对子进程来说，之所以 fork 返回 0 给它，是因为它随时可以调用 getpid（） 来获取自己的 pid；也可以调用 getppid（） 来获取父进程的 id。（进程 id 0 总是由交换进程使用，所以一个子进程的进程 id 不可能为 0 ）。
> fork 之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来，他们更像兄弟关系，这 2 个进程共享代码空间，但是数据空间是互相独立的，子进程数据空间中的内容是父进程的完整拷贝，指令指针也完全相同，子进程拥有父进程当前运行到的位置（两进程的程序计数器 pc 值相同，也就是说，子进程是从 fork 返回处开始执行的），但有一点不同，如果 fork 成功，子进程中 fork 的返回值是 0，父进程中 fork 的返回值是子进程的进程号，如果 fork 不成功，父进程会返回错误。
> 可以这样想象，2 个进程一直同时运行，而且步调一致，在 fork 之后，他们分别做不同的工作，也就是分岔了。这也是 fork 为什么叫 fork 的原因。
> 至于那一个最先运行，可能与操作系统（调度算法）有关，而且这个问题在实际应用中并不重要，如果需要父子进程协同，可以通过原语的办法解决。

常见的通信方式：
1. （匿名）管道 pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
2. 有名管道 FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
3. 高级管道 popen：将另一个程序当做一个新的进程在当前程序进程中启动，则它算是当前程序的子进程，这种方式我们成为高级管道方式。
4. 消息队列 Message Queue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
5. 共享存储 Shared Memory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
6. 信号量 Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
7. 套接字 Socket：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。
8. 信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。


进程间通信的概念
每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程 1 把数据从用户空间拷到内核缓冲区，进程 2 再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信（IPC，InterProcess Communication）。


进程间通信的 7 种方式

第一类：传统的 Unix 通信机制

1. 管道 / 匿名管道（pipe）
- 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道。
- 只能用于父子进程或者兄弟进程之间（具有亲缘关系的进程）；
- 单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。
- 数据的读出和写入：一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。

管道的实质：
管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。

该缓冲区可以看做是一个循环队列，读和写的位置都是自动增长的，不能随意改变，一个数据只能被读一次，读出来以后在缓冲区就不复存在了。
当缓冲区读空或者写满时，有一定的规则控制相应的读进程或者写进程进入等待队列，当空的缓冲区有新数据写入或者满的缓冲区有数据读出来时，就唤醒等待队列中的进程继续读写。

管道的特点和局限性：
- 只支持单向数据流；
- 只能用于具有亲缘关系的进程之间；
- 没有名字；
- 管道的缓冲区是有限的（管道制存在于内存中，在管道创建时，为缓冲区分配一个页面大小）；
- 管道所传送的是无格式字节流，这就要求管道的读出方和写入方必须事先约定好数据的格式，比如多少字节算作一个消息（或命令、或记录）等等；
- 依赖于文件系统，它的生命周期随进程的结束结束（随进程）
- 其本身自带同步互斥效果

int pipe（int pipefd[2]）
pid_t fork（void）；

2. 有名管道（FIFO）
匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道（FIFO）。
有名管道不同于匿名管道之处在于：
它提供了一个路径名与之关联，以有名管道的文件形式存在于文件系统中，这样，即使与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过有名管道相互通信，因此，通过有名管道不相关的进程也能交换数据。值的注意的是，有名管道严格遵循先进先出（first in first out），对匿名管道及有名管道的读总是从开始处返回数据，对它们的写则把数据添加到末尾。它们不支持诸如 lseek（）等文件定位操作。有名管道的名字存在于文件系统中，内容存放在内存中。

匿名管道和有名管道总结：
（1）管道是特殊类型的文件，在满足先入先出的原则条件下可以进行读写，但不能进行定位读写。
（2）匿名管道是单向的，只能在有亲缘关系的进程间通信；有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。
（3）无名管道阻塞问题：无名管道无需显示打开，创建时直接返回文件描述符，在读写时需要确定对方的存在，否则将退出。如果当前进程向无名管道的一端写数据，必须确定另一端有某一进程。如果写入无名管道的数据超过其最大值，写操作将阻塞，如果管道中没有数据，读操作将阻塞，如果管道发现另一端断开，将自动退出。
（4）有名管道阻塞问题：有名管道在打开时需要确实对方的存在，否则将阻塞。即以读方式打开某管道，在此之前必须一个进程以写方式打开管道，否则阻塞。此外，可以以读写（O_RDWR）模式打开有名管道，即当前进程读，当前进程写，不会阻塞。命名管道使用之前需要使用 open（）打开。这是因为：命名管道是设备文件，它是存储在硬盘上的，而管道是存在内存中的特殊文件。但是需要注意的是，命名管道调用 open（）打开有可能会阻塞，但是如果以读写方式（O_RDWR）打开则一定不会阻塞；以只读（O_RDONLY）方式打开时，调用 open（）的函数会被阻塞直到有数据可读；如果以只写方式（O_WRONLY）打开时同样也会被阻塞，知道有以读方式打开该管道。

匿名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统

命名管道
1、与管道的区别：提供了一个路径名与之关联，以 FIFO 文件的形式存储于文件系统中，能够实现任何两个进程之间通信。而匿名管道对于文件系统是不可见的，它仅限于在父子进程之间的通信。
2、FIFO 是一个设备文件，在文件系统中以文件名的形式存在，因此即使进程与创建 FIFO 的进程不存在血缘关系也依然可以通信，前提是可以访问该路径。
3、FIFO（first input first output）总是遵循先进先出的原则，即第一个进来的数据会第一个被读走。


* 匿名管道和命名管道_YANG-CSDN 博客 
    * https：//blog.csdn.net/qq_33951180/article/details/68959819

个人总结管道和命名管道 关键词：
管道：
1、单双工
2、亲缘进程（父子进程）
3、字节流
4、依赖文件系统，进程结束即关闭
5、自带同步互斥

命名管道 vs 匿名管道：
1、任何进程 vs 父子进程
2、路径名 vs 无名，FIFO 文件 vs 内存特殊文件
3、FIFO vs ？


3. 信号（Signal）

信号是 Linux 系统中用于进程间互相通信或者操作的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。
如果该进程当前并未处于执行状态，则该信号就有内核保存起来，知道该进程回复执行并传递给它为止。
如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消是才被传递给进程。

Linux 系统中常用信号：
（1）SIGHUP：用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程。
（2）SIGINT：程序终止信号。程序运行过程中，按 Ctrl+C 键将产生该信号。
（3）SIGQUIT：程序退出信号。程序运行过程中，按 Ctrl+\\ 键将产生该信号。
（4）SIGBUS 和 SIGSEGV：进程访问非法地址。
（5）SIGFPE：运算中出现致命错误，如除零操作、数据溢出等。
（6）SIGKILL：用户终止进程执行信号。shell 下执行 kill -9 发送该信号。
（7）SIGTERM：结束进程信号。shell 下执行 kill 进程 pid 发送该信号。
（8）SIGALRM：定时器信号。
（9）SIGCLD：子进程退出信号。如果其父进程没有忽略该信号也没有处理该信号，则子进程退出后将形成僵尸进程。

信号来源
信号是软件层次上对中断机制的一种模拟，是一种异步通信方式，，信号可以在用户空间进程和内核之间直接交互，内核可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件主要有两个来源：
硬件来源：用户按键输入 Ctrl+C 退出、硬件异常如无效的存储访问等。
软件终止：终止进程信号、其他进程调用 kill 函数、软件异常产生信号。

信号生命周期和处理流程
（1）信号被某个进程产生，并设置此信号传递的对象（一般为对应进程的 pid），然后传递给操作系统；
（2）操作系统根据接收进程的设置（是否阻塞）而选择性的发送给接收者，如果接收者阻塞该信号（且该信号是可以阻塞的），操作系统将暂时保留该信号，而不传递，直到该进程解除了对此信号的阻塞（如果对应进程已经退出，则丢弃此信号），如果对应进程没有阻塞，操作系统将传递此信号。
（3）目的进程接收到此信号后，将根据当前进程对此信号设置的预处理方式，暂时终止当前代码的执行，保护上下文（主要包括临时寄存器数据，当前程序位置以及当前 CPU 的状态）、转而执行中断服务程序，执行完成后再恢复到中断的位置。当然，对于抢占式内核，在中断返回时还将引发新的调度。

4. 消息（Message）队列

消息队列是存放在内核中的消息链表，每个消息队列由消息队列标识符表示。
与管道不同的是：
- 消息队列存放在内核中，只有在内核重启（即，操作系统重启）或者显式地删除一个消息队列时，该消息队列才会被真正的删除。
- 消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达。

消息队列特点总结：
（1）消息队列是消息的链表，具有特定的格式，存放在内存中并由消息队列标识符标识.
（2）消息队列允许一个或多个进程向它写入与读取消息.
（3）管道和消息队列的通信数据都是先进先出的原则。
（4）消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可以按消息的类型读取. 比 FIFO 更有优势。
（5）消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺。
（6）目前主要有两种类型的消息队列：POSIX 消息队列以及 System V 消息队列，系统 V 消息队列目前被大量使用。系统 V 消息队列是随内核持续的，只有在内核重起或者人工删除时，该消息队列才会被删除。


5. 共享内存（share memory）

使得多个进程可以可以直接读写同一块内存空间，是最快的可用 IPC 形式。是针对其他通信机制运行效率较低而设计的。
为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。
由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。

6. 信号量（semaphore）

信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。
为了获得共享资源，进程需要执行下列操作：
（1）创建一个信号量：这要求调用者指定初始值，对于二值信号量来说，它通常是 1，也可是 0。
（2）等待一个信号量（P 操作，wait）：该操作会测试这个信号量的值，如果 <= 0，就阻塞，否则 - 1，执行，。申请一个单位资源，进程进入。
（3）挂出一个信号量（V 操作，signal）：该操作将信号量的值 +1。释放一个单位资源，进程出来。

为了正确地实现信号量，信号量值的测试及减 1 操作应当是原子操作。为此，信号量通常是在内核中实现的。Linux 环境中，有三种类型：Posix（可移植性操作系统接口）有名信号量（使用 Posix IPC 名字标识）、Posix 基于内存的信号量（存放在共享内存区中）、System V 信号量（在内核中维护）。这三种信号量都可用于进程间或线程间的同步。

信号量与普通整型变量的区别：
（1）信号量是非负整型变量，除了初始化之外，它只能通过两个标准原子操作：wait（semap） ， signal（semap） 来进行访问；
（2）操作也被成为 PV 原语（P 来源于荷兰语 proberen“测试”，V 来源于荷兰语 verhogen“增加”，P 表示通过的意思，V 表示释放的意思），而普通整型变量则可以在任何语句块中被访问；

信号量与互斥量之间的区别：
（1）互斥量用于线程的互斥，信号量用于线程的同步。这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别。
互斥：是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。
同步：是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。
在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源
（2）互斥量值只能为 0/1，信号量值可以为非负整数。
也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。信号量可以实现多个同类资源的多线程互斥和同步。当信号量为单值信号量是，也可以完成一个资源的互斥访问。
（3）互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。

7. 套接字（socket）
套接字是一种通信机制，凭借这种机制，客户 / 服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让不在同一台计算机但通过网络连接计算机上的进程进行通信。

套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

套接字特性
套接字的特性由 3 个属性确定，它们分别是：域、端口号、协议类型。
（1）套接字的域
它指定套接字通信中使用的网络介质，最常见的套接字域有两种：
一是 AF_INET，它指的是 Internet 网络。当客户使用套接字进行跨网络的连接时，它就需要用到服务器计算机的 IP 地址和端口来指定一台联网机器上的某个特定服务，所以在使用 socket 作为通信的终点，服务器应用程序必须在开始通信之前绑定一个端口，服务器在指定的端口等待客户的连接。
另一个域 AF_UNIX，表示 UNIX 文件系统，它就是文件输入 / 输出，而它的地址就是文件名。
（2）套接字的端口号
    * 计算机网络常用端口 - osoft - 博客园 
        * https：//www.cnblogs.com/sztom/p/10810834.html
每一个基于 TCP/IP 网络通讯的程序（进程）都被赋予了唯一的端口和端口号，端口是一个信息缓冲区，用于保留 Socket 中的输入 / 输出信息，端口号是一个 16 位无符号整数，范围是 0-65535，以区别主机上的每一个程序（端口号就像房屋中的房间号），低于 256 的端口号保留给标准应用程序，比如 pop3 的端口号就是 110，每一个套接字都组合进了 IP 地址、端口，这样形成的整体就可以区别每一个套接字。
（3）套接字协议类型
因特网提供三种通信机制，
一是流套接字，流套接字在域中通过 TCP/IP 连接实现，同时也是 AF_UNIX 中常用的套接字类型。流套接字提供的是一个有序、可靠、双向字节流的连接，因此发送的数据可以确保不会丢失、重复或乱序到达，而且它还有一定的出错后重新发送的机制。
二个是数据报套接字，它不需要建立连接和维持一个连接，它们在域中通常是通过 UDP/IP 协议实现的。它对可以发送的数据的长度有限制，数据报作为一个单独的网络消息被传输，它可能会丢失、复制或错乱到达，UDP 不是一个可靠的协议，但是它的速度比较高，因为它并一需要总是要建立和维持一个连接。
三是原始套接字，原始套接字允许对较低层次的协议直接访问，比如 IP、 ICMP 协议，它常用于检验新的协议实现，或者访问现有服务中配置的新设备，因为 RAW SOCKET 可以自如地控制 Windows 下的多种协议，能够对网络底层的传输机制进行控制，所以可以应用原始套接字来操纵网络层和传输层应用。比如，我们可以通过 RAW SOCKET 来接收发向本机的 ICMP、IGMP 协议包，或者接收 TCP/IP 栈不能够处理的 IP 包，也可以用来发送一些自定包头或自定协议的 IP 包。网络监听技术很大程度上依赖于 SOCKET_RAW。

原始套接字与标准套接字的区别在于：
原始套接字可以读写内核没有处理的 IP 数据包，而流套接字只能读取 TCP 协议的数据，数据报套接字只能读取 UDP 协议的数据。因此，如果要访问其他协议发送数据必须使用原始套接字。

套接字通信的建立
    * Socket 过程详细解释（包括三次握手建立连接，四次握手断开连接）_猫叔 66 的博客 - CSDN 博客 
        * https：//blog.csdn.net/qq_31209383/article/details/54845985

    * 什么是套接字（Socket）_wangluqinglxq 的专栏 - CSDN 博客 
        * https：//blog.csdn.net/wangluqinglxq/article/details/38402759

服务器端
（1）首先服务器应用程序用系统调用 socket 来创建一个套接字，它是系统分配给该服务器进程的类似文件描述符的资源，它不能与其他的进程共享。
（2）然后，服务器进程会给套接字起个名字，我们使用系统调用 bind 来给套接字命名。然后服务器进程就开始等待客户连接到这个套接字。
（3）接下来，系统调用 listen 来创建一个队列并将其用于存放来自客户的进入连接。
（4）最后，服务器通过系统调用 accept 来接受客户的连接。它会创建一个与原有的命名套接不同的新套接字，这个套接字只用于与这个特定客户端进行通信，而命名套接字（即原先的套接字）则被保留下来继续处理来自其他客户的连接（建立客户端和服务端的用于通信的流，进行通信）。

客户端
（1）客户应用程序首先调用 socket 来创建一个未命名的套接字，然后将服务器的命名套接字作为一个地址来调用 connect 与服务器建立连接。
（2）一旦连接建立，我们就可以像使用底层的文件描述符那样用套接字来实现双向数据的通信（通过流进行数据传输）。

1、socket() 函数
    int socket(int domain， int type， int protocol);
socket 函数对应于普通文件的打开操作。普通文件的打开操作返回一个文件描述字，而 socket() 用于创建一个 socket 描述符（socket descriptor），它唯一标识一个 socket。这个 socket 描述字跟文件描述字一样，后续的操作都有用到它，把它作为参数，通过它来进行一些读写操作。
domain：即协议域，又称为协议族（family）。常用的协议族有，AF_INET……
type：指定 socket 类型。常用的 socket 类型有，SOCK_STREAM、SOCK_DGRAM、SOCK_RAW、SOCK_PACKET……
protocol：故名思意，就是指定协议。常用的协议有，IPPROTO_TCP、IPPTOTO_UDP……

2、bind() 函数
    int bind(int sockfd， const struct sockaddr *addr， socklen_t addrlen);
正如上面所说 bind() 函数把一个地址族中的特定地址赋给 socket。例如对应 AF_INET、AF_INET6 就是把一个 ipv4 或 ipv6 地址和端口号组合赋给 socket。
函数的三个参数分别为：
sockfd：即 socket 描述字，它是通过 socket() 函数创建了，唯一标识一个 socket。bind() 函数就是将给这个描述字绑定一个名字。
addr：一个 const struct sockaddr * 指针，指向要绑定给 sockfd 的协议地址。
addrlen：对应的是地址的长度。

3、listen()、connect() 函数
如果作为一个服务器，在调用 socket()、bind() 之后就会调用 listen() 来监听这个 socket，如果客户端这时调用 connect() 发出连接请求，服务器端就会接收到这个请求。
    int listen(int sockfd， int backlog);
listen 函数的第一个参数即为要监听的 socket 描述字，第二个参数为相应 socket 可以排队的最大连接个数。socket() 函数创建的 socket 默认是一个主动类型的，listen 函数将 socket 变为被动类型的，等待客户的连接请求。
    int connect(int sockfd， const struct sockaddr *addr， socklen_t addrlen);
connect 函数的第一个参数即为客户端的 socket 描述字，第二参数为服务器的 socket 地址，第三个参数为 socket 地址的长度。客户端通过调用 connect 函数来建立与 TCP 服务器的连接。

4、accept() 函数
TCP 服务器端依次调用 socket()、bind()、listen() 之后，就会监听指定的 socket 地址了。TCP 客户端依次调用 socket()、connect() 之后就想 TCP 服务器发送了一个连接请求。TCP 服务器监听到这个请求之后，就会调用 accept() 函数取接收请求，这样连接就建立好了。之后就可以开始网络 I/O 操作了，即类同于普通文件的读写 I/O 操作。
    int accept(int sockfd， struct sockaddr *addr， socklen_t *addrlen);
accept 函数的第一个参数为服务器的 socket 描述字，第二个参数为指向 struct sockaddr * 的指针，用于返回客户端的协议地址，第三个参数为协议地址的长度。如果 accpet 成功，那么其返回值是由内核自动生成的一个全新的描述字，代表与返回客户的 TCP 连接。


5、read()、write() 等函数
万事具备只欠东风，至此服务器与客户已经建立好连接了。可以调用网络 I/O 进行读写操作了，即实现了网咯中不同进程之间的通信！网络 I/O 操作有下面几组：
    read()/write()
    recv()/send()
    readv()/writev()
    recvmsg()/sendmsg()
    recvfrom()/sendto()

6、close() 函数
在服务器与客户端建立连接之后，会进行一些读写操作，完成了读写操作就要关闭相应的 socket 描述字，好比操作完打开的文件要调用 fclose 关闭打开的文件。
    #include <unistd.h>
    int close(int fd);

<!-- ### 线程池 -->

## 死锁的必要条件和解决

* 什么是死锁 (deadlock)？__牛客网 
    * https://www.nowcoder.com/questionTerminal/09b51b00891543d6b08ace80c0704b01
* CS-Notes / 计算机操作系统 - 死锁. md at master · CyC2018/CS-Notes 
    * https://github.com/CyC2018/CS-Notes/blob/master/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E6%AD%BB%E9%94%81.md
* 死锁的四个必要条件和解决办法_半暖的博客 - CSDN 博客 
    * https://blog.csdn.net/guaiguaihenguai/article/details/80303835

死锁 : 是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用, 它们都将无法推进下去：
（1）因为系统资源不足或分配不当
（2）进程运行推进顺序不合适。

如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则
就会因争夺有限的资源而陷入死锁。其次，进程运行推进顺序与速度不同，也可能产生死锁。

这四个条件是死锁的必要条件，只要死锁，这些条件必然成立，其中之一不满足，就不会发生死锁。
（1）互斥条件：一个资源每次只能被一个进程使用。
（2）请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
（3）不剥夺条件: 进程已获得的资源，在末使用完之前，不能强行剥夺。
（4）循环等待条件: 若干进程之间形成一种头尾相接的循环等待资源关系。

死锁的解除与预防：
在系统设计、进程调度等方面注意如何不让这四个必要条件成立，如何确
定资源的合理分配算法，避免进程永久占据系统资源。此外，也要防止进程在处于等待状态
的情况下占用资源。因此，对资源的分配要给予合理的规划。


死锁概念及产生原理
    概念： 多个并发进程因争夺系统资源而产生相互等待的现象。
    原理： 当一组进程中的每个进程都在等待某个事件发生，而只有这组进程中的其他进程才能触发该事件，这就称这组进程发生了死锁。
    本质原因：
        1）、系统资源有限。
        2）、进程推进顺序不合理。

死锁产生的 4 个必要条件
    1、互斥： 某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束。
    2、占有且等待：一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源。
    3、不可抢占：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。
    4、循环等待：存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源。
当以上四个条件均满足，必然会造成死锁，发生死锁的进程无法进行下去，它们所持有的资源也无法释放。这样会导致 CPU 的吞吐量下降。所以死锁情况是会浪费系统资源和影响计算机的使用性能的。那么，解决死锁问题就是相当有必要的了。


1、死锁预防：确保系统永远不会进入死锁状态
    产生死锁需要四个条件，那么，只要这四个条件中至少有一个条件得不到满足，就不可能发生死锁了。
    由于互斥条件是非共享资源所必须的，不仅不能改变，还应加以保证，所以，主要是破坏产生死锁的其他三个条件。
a、破坏 “占有且等待” 条件
     方法 1：所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源。
         优点：简单易实施且安全。
         缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，严重降低了资源的利用率，造成资源浪费。使进程经常发生饥饿现象。
     方法 2：该方法是对第一种方法的改进，允许进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到的已经使用完毕的资源，然后再去请求新的资源。这样的话，资源的利用率会得到提高，也会减少进程的饥饿问题。
b、破坏 “不可抢占” 条件
      当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。这就意味着进程已占有的资源会被短暂地释放或者说是被抢占了。
      该种方法实现起来比较复杂，且代价也比较大。释放已经保持的资源很有可能会导致进程之前的工作失效等，反复的申请和释放资源会导致进程的执行被无限的推迟，这不仅会延长进程的周转周期，还会影响系统的吞吐量。
c、破坏 “循环等待” 条件
     可以通过定义资源类型的线性顺序来预防，可将每个资源编号，当一个进程占有编号为 i 的资源时，那么它下一次申请资源只能申请编号大于 i 的资源。
    这样虽然避免了循环等待，但是这种方法是比较低效的，资源的执行速度回变慢，并且可能在没有必要的情况下拒绝资源的访问，比如说，进程 c 想要申请资源 1，如果资源 1 并没有被其他进程占有，此时将它分配给进程 c 是没有问题的，但是为了避免产生循环等待，该申请会被拒绝，这样就降低了资源的利用率

2、避免死锁：在使用前进行判断，只允许不会产生死锁的进程申请资源
死锁避免是利用额外的检验信息，在分配资源时判断是否会出现死锁，只在不会出现死锁的情况下才分配资源。
两种避免办法：
    1、如果一个进程的请求会导致死锁，则不启动该进程
    2、如果一个进程的增加资源请求会导致死锁，则拒绝该申请。


避免死锁的具体实现通常利用银行家算法
银行家算法
a、银行家算法的相关数据结构
- 可利用资源向量 Available：用于表示系统里边各种资源剩余的数目。由于系统里边拥有的资源通常都是有很多种（假设有 m 种），所以，我们用一个有 m 个元素的数组来表示各种资源。数组元素的初始值为系统里边所配置的该类全部可用资源的数目，其数值随着该类资源的分配与回收动态地改变。
- 最大需求矩阵 Max：用于表示各个进程对各种资源的额最大需求量。进程可能会有很多个（假设为 n 个），那么，我们就可以用一个 n x m 的矩阵来表示各个进程多各种资源的最大需求量
- 分配矩阵 Allocation：顾名思义，就是用于表示已经分配给各个进程的各种资源的数目。也是一个 n x m 的矩阵。
- 需求矩阵 Need：用于表示进程仍然需要的资源数目，用一个 n x m 的矩阵表示。系统可能没法一下就满足了某个进程的最大需求（通常进程对资源的最大需求也是指它在 ** 整个运行周期 ** 中需要的资源数目，并不是每一个时刻都需要这么多），于是，为了进程的执行能够向前推进，通常，系统会先分配个进程一部分资源保证进程能够执行起来。那么，进程的最大需求减去已经分配给进程的数目，就得到了进程仍然需要的资源数目了。

银行家算法通过对进程需求、占有和系统拥有资源的实时统计，确保系统在分配给进程资源不会造成死锁才会给与分配。
死锁避免的优点：不需要死锁预防中的抢占和重新运行进程，并且比死锁预防的限制要少。
死锁避免的限制：
    1、必须事先声明每个进程请求的最大资源量
    2、考虑的进程必须无关的，也就是说，它们执行的顺序必须没有任何同步要求的限制
    3、分配的资源数目必须是固定的。
    4、在占有资源时，进程不能退出

上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。

检查一个状态是否安全的算法如下：
- 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
- 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
- 重复以上两步，直到所有进程都标记为终止，则状态时安全的。
如果一个状态不是安全的，需要拒绝进入这个状态。


上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。
图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。
每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

3、死锁检测与解除：在检测到运行系统进入死锁，进行恢复。
允许系统进入到死锁状态
死锁的解除
如果利用死锁检测算法检测出系统已经出现了死锁，常用的解除死锁的方法：
1、抢占资源：从一个或多个进程中抢占足够数量的资源分配给死锁进程，以解除死锁状态。
2、终止（或撤销）进程：终止或撤销系统中的一个或多个死锁进程，直至打破死锁状态。
    a、终止所有的死锁进程。这种方式简单粗暴，但是代价很大，很有可能会导致一些已经运行了很久的进程前功尽弃。
    b、逐个终止进程，直至死锁状态解除。该方法的代价也很大，因为每终止一个进程就需要使用死锁检测来检测系统当前是否处于死锁状态。另外，每次终止进程的时候终止那个进程呢？每次都应该采用最优策略来选择一个 “代价最小” 的进程来解除死锁状态。
    一般根据如下几个方面来决定终止哪个进程：
    - 进程的优先级
    - 进程已运行时间以及运行完成还需要的时间
    - 进程已占用系统资源
    - 进程运行完成还需要的资源
    - 终止进程数目
    - 进程是交互还是批处理

## Cookie、Session
* Http 协议中 Cookie 详细介绍 - 李小菜丶 - 博客园 
    * https://www.cnblogs.com/bq-med/p/8603664.html
* HTTP 协议 - Cookie 和 Session 详解 - _四点 - 博客园 
    * https://www.cnblogs.com/humiao-0626/p/11347764.html
    
Cookie 总是保存在客户端中，按在客户端中的存储位置，可分为内存 Cookie 和硬盘 Cookie。内存 Cookie 由浏览器维护，保存在内存中，浏览器关闭后就消失了，其存在时间是短暂的。硬盘 Cookie 保存在硬盘里，有一个过期时间，除非用户手工清理或到了过期时间，硬盘 Cookie 不会被删除，其存在时间是长期的。所以，按存在时间，可分为非持久 Cookie 和持久 Cookie。

cookie 的属性
一般 cookie 所具有的属性，包括：
Domain：域，表示当前 cookie 所属于哪个域或子域下面。对于服务器返回的 Set-Cookie 中，如果没有指定 Domain 的值，那么其 Domain 的值是默认为当前所提交的 http 的请求所对应的主域名的。比如访问 http://www.example.com，返回一个 cookie，没有指名 domain 值，那么其为值为默认的 www.example.com。
Path：表示 cookie 的所属路径。
Expire time/Max-age：表示了 cookie 的有效期。expire 的值，是一个时间，过了这个时间，该 cookie 就失效了。或者是用 max-age 指定当前 cookie 是在多长时间之后而失效。如果服务器返回的一个 cookie，没有指定其 expire time，那么表明此 cookie 有效期只是当前的 session，即是 session cookie，当前 session 会话结束后，就过期了。对应的，当关闭（浏览器中）该页面的时候，此 cookie 就应该被浏览器所删除了。
secure：表示该 cookie 只能用 https 传输。一般用于包含认证信息的 cookie，要求传输此 cookie 的时候，必须用 https 传输。
httponly：表示此 cookie 必须用于 http 或 https 传输。这意味着，浏览器脚本，比如 javascript 中，是不允许访问操作此 cookie 的。

服务器发送 cookie 给客户端
从服务器端，发送 cookie 给客户端，是对应的 Set-Cookie。包括了对应的 cookie 的名称，值，以及各个属性。

从客户端把 cookie 发送到服务器
从客户端发送 cookie 给服务器的时候，是不发送 cookie 的各个属性的，而只是发送对应的名称和值。

Cookie 的缺陷
- cookie 会被附加在每个 HTTP 请求中，所以无形中增加了流量。
- 由于在 HTTP 请求中的 cookie 是明文传递的，所以安全性成问题。（除非用 HTTPS)
- Cookie 的大小限制在 4KB 左右。对于复杂的存储需求来说是不够用的。


除了使用 cookie，Web 应用程序中还经常使用 Session 来记录客户端状态。Session 是服务器端使用的一种记录客户端状态的机制，使用上比 Cookie 简单一些，相应的也增加了服务器的存储压力。

1. 什么是 Session
Session 是另一种记录客户状态的机制，不同的是 Cookie 保存在客户端浏览器中，Session 保存在服务器上。客户端浏览器访问服务器的时候，服务端把客户端信息以某种形式记录在服务器上，这就是 Session。客户端浏览器再次访问时只需要从该 Session 中查找该客户的状态就可以了。
如果说 Cookie 机制是通过检查客户身上的 "通行证" 来确定客户身份的话，那么 Session 及时就是通过检查服务器上的 "客户明细表" 来确认身份。Session 相当于程序在服务器上建立的一份客户档案，客户来访时只需要检查客户的档案表就可以了。

2. 实现用户登录
提示：Session 的使用比 Cookie 方便，但是过多的 Session 存储在服务器内存中，会对服务器造成压力。

3.Session 的生命周期
Session 保存在服务器端。为了获得更高的存取速度，服务器一般吧 Session 放在内存里。每个用户都会有一个独立的 Session。如果 Session 内用过于复杂，当大量客户访问服务器时可能导致内存溢出。因此，Session 里的信息尽量精简。
Session 在用户第一次访问服务器的时候自动创建。需要注意只有访问 JSP、Serviet 等程序时才会创建 Session，只访问 HTML、IMAGE 等静态资源并不会创建 Session。如果尚未生成 Session，也可能使用 request.getSession（true）强制生成 Session。
Session 生成后，只要用户继续访问，服务器就会更新 Session 的最后访问时间，并维护该 Session。用户每访问一次，无论是否读写 Session，服务器都认为该用户的 Session 活跃（active）了一次。

4.Session 的有效期
由于有越来越多的用户访问服务器，因此 Session 也会越来越多。为防止内存溢出，服务器会把长时间没有活跃的 Session 从内存中删除。这个时间就是 Session 的超时时间。如果超过了超时时间没有访问过服务器，Session 就自动失效。

通过调用 Session 的 invalidate() 方法可以使 Session 失效。

6.Session 对浏览器的要求
虽然 Session 保存在服务器，对客户端是透明的，他的正常运行任然需要客户端浏览器的支持。这是因为 Session 需要使用 Cookie 作为识别标志。HTTP 协议是无状态的，Session 不能依据 HTTP 链接来判断是否为同一客户，因此服务器先客户端浏览器发送一个名为 JSESSIONID 的 Cookie，他的值为该 Session 的 id（也就是 HTTPSession.getId() 的返回值）。Session 依据 Cookie 来识别是否为同一用户。

该 Cookie 为服务器自动生成的，它的 maxAge 属性一般为 -1，表示仅当前浏览器内有效，并且个浏览器窗口间不共享，关闭浏览器就会失效。

因此同一机器的两个浏览器窗口访问服务器时，会生成两个不同的 Session、但是由浏览器窗口内的链接、脚本等打开的新窗口（也就是说不是双击 = 桌面浏览器图标打开的窗口）除外。这类子窗口会共享父窗口的 Cookie，因此会共享一个 Session。

如果客户端浏览器将 Cookie 功能禁用，或者不支持 Cookie 怎么办？例如，绝大多数的手机浏览器都不支持 Cookie。Java Web 提供了另一种解决方案：URL 地址重写。

8.Session 中禁止使用 Cookie
既然既然 WAP 上大部分的客户浏览器都不支持 Cookie，索性禁止 Session 使用 Cookie，统一使用 URL 地址重写会更好一些。

## 进程的状态
* 进程状态（含状态变迁图）_qicheng777 的博客 - CSDN 博客 
    * https://blog.csdn.net/qicheng777/article/details/77427157

就绪 运行 阻塞

## 进程 / 线程同步

（1）信号量机制
一个信号量只能置一次初值，以后只能对之进行p操作或v操作。 由此也可以看到，信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点。 

（2）自旋锁
 旋锁是为了保护共享资源提出的一种锁机制。 调用者申请的资源如果被占用，即自旋锁被已经被别的执行单元保持，则调用者一直循环在那里看是否该自旋锁的保持着已经释放了锁，自旋锁是一种比较低级的保护数据结构和代码片段的原始方式，可能会引起以下两个问题; 
a.死锁 
b.过多地占用CPU资源 
（3）管程
信号量机制功能强大，但使用时对信号量的操作分散，而且难以控制，读写和维护都很困难。因此后来又提出了一种集中式同步进程——管程。其基本思想是将共享变量和对它们的操作集中在一个模块中，操作系统或并发程序就由这样的模块构成。这样模块之间联系清晰，便于维护和修改，易于保证正确性。 
（4）会合
 进程直接进行相互作用
（5）分布式系统
 由于在分布式操作系统中没有公共内存，因此参数全为值参，而且不可为指针。

## 进程调度

* 操作系统中常用的进程调度算法_Hopefully Sky 的博客 - CSDN 博客 
    * https://blog.csdn.net/fuzhongmin05/article/details/55802925
* 五种进程调度算法的总结; - 简书 
    * https://www.jianshu.com/p/ecfddbc0af2d

1、先来先服务调度算法（FCFS）：根据进程到达的先后顺序执行进程，不考虑等待时间和执行时间，会产生饥饿现象。属于非抢占式调度。
    优点是公平，实现简单；缺点是不利于短作业。
2、时间片轮转调度算法（RR）：给每个进程固定的执行时间，根据进程到达的先后顺序让进程在单位时间片内执行，执行完成后便调度下一个进程执行，时间片轮转调度不考虑进程等待时间和执行时间，属于抢占式调度。
    优点是兼顾长短作业；缺点是平均等待时间较长，上下文切换较费时。适用于分时系统。
3、优先级调度算法（HPF）：在进程等待队列中选择优先级最高的来执行。
4、多级反馈队列调度算法：将时间片轮转与优先级调度相结合，把进程按优先级分成不同的队列，先按优先级调度，优先级相同的，按时间片轮转。
    优点是兼顾长短作业，有较好的响应时间，可行性强，适用于各种作业环境。
5、高响应比优先调度算法：根据 “响应比 =（进程执行时间 + 进程等待时间）/ 进程执行时间” 这个公式得到的响应比来进行调度。高响应比优先算法在等待时间相同的情况下，作业执行的时间越短，响应比越高，满足段任务优先，同时响应比会随着等待时间增加而变大，优先级会提高，能够避免饥饿现象。
优点是兼顾长短作业，缺点是计算响应比开销大，适用于批处理系统。


1、先来先服务调度算法
先来先服务 (FCFS) 调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用 FCFS 算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。

2、短作业 (进程) 优先调度算法
短作业 (进程) 优先调度算法，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先 (SJF) 的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先 (SPF) 调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。

3、时间片轮转法
在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几 ms 到几百 ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。 

4、多级反馈队列调度算法
前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程如下所述：

1）应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，第 i+1 个队列的时间片要比第 i 个队列的时间片长一倍。

2）当一个新进程进入内存后，首先将它放入第一队列的末尾，按 FCFS 原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按 FCFS 原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业 (进程) 从第一队列依次降到第 n 队列后，在第 n 队列便采取按时间片轮转的方式运行。

3）仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第 1～(i-1) 队列均空时，才会调度第 i 队列中的进程运行。如果处理机正在第 i 队列中为某进程服务时，又有新进程进入优先权较高的队列 (第 1～(i-1) 中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即第 i 队列中某个正在运行的进程的时间片用完后，由调度程序选择优先权较高的队列中的那一个进程，把处理机分配给它。

5、优先权调度算法
为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先 (FPF) 调度算法。此算法常被用于批处理系统中，作为作业调度算法，也作为多种操作系统中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分成如下两种。

1) 非抢占式优先权算法
在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。

2) 抢占式优先权调度算法
在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程 (原优先权最高的进程) 的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程 i 时，就将其优先权 Pi 与正在执行的进程 j 的优先权 Pj 进行比较。如果 Pi≤Pj，原进程 Pj 便继续执行；但如果是 Pi>Pj，则立即停止 Pj 的执行，做进程切换，使 i 进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。


## 分页和分段

## 页面置换算法

### MapReduce
分片怎么读的，为什么用快排，换别的行不行，多路归并怎么实现的，环形缓冲区怎么实现的。

* MapReduce 工作原理流程简介 - 废物大师兄 - 博客园 
    * https://www.cnblogs.com/cjsblog/p/8168642.html
* MapReduce 的基本工作原理_fanxin_i 的博客 - CSDN 博客 
    * https://blog.csdn.net/fanxin_i/article/details/80388221

MapReduce 的基本模型和处理思想：
三个层面上的基本构思
1. 如果对付大数据处理：分而治之
    对相互之间不具有计算依赖关系的大数据，实现并行最自然的办法就是采取分而治之的策略。
2. 上升到抽象模型：Mapper 与 Reduce
    MPI 等并行计算方法缺少高层并行编程模型，程序员需要自行指定存储，计算，分发等任务，为了克服这一缺陷，MapReduce 借鉴了 Lisp 函数式语言中的思想，用 Map 和 Reduce 两个函数提供了高层的并发编程模型抽象。
3. 上升到架构：统一架构，为程序员隐藏系统层细节
   MPI 等并行计算方法缺少统一的计算框架支持，程序员需要考虑数据存储、划分、分发、结果收集、错误恢复等诸多细节；为此, MapReduce 设计并提供了同意的计算框架，为程序员隐藏了绝大多数系统层面的处理系统。
大数据分而治之

1. 有一个待处理的大数据，被划分成大小相同的数据库 (如 64MB)，以及与此相应的用户作业程序。
2. 系统中有一个负责调度的主节点 (Master)，以及数据 Map 和 Reduce 工作节点 (Worker).
3. 用户作业提交各主节点。
4. 主节点为作业程序寻找和配备可用的 Map 节点，并将程序传送给 map 节点。
5. 主节点也为作业程序寻找和配备可用的 Reduce 节点，并将程序传送给 Reduce 节点。
6. 主节点启动每一个 Map 节点执行程序，每个 Map 节点尽可能读取本地或本机架的数据进行计算。(实现代码向数据靠拢，减少集群中数据的通信量)。
7. 每个 Map 节点处理读取的数据块，并做一些数据整理工作 (combining,sorting 等) 并将数据存储在本地机器上；同时通知主节点计算任务完成并告知主节点中间结果数据的存储位置。
8. 主节点等所有 Map 节点计算完成后，开始启动 Reduce 节点运行；Reduce 节点从主节点所掌握的中间结果数据位置信息，远程读取这些数据。
9.Reduce 节点计算结果汇总输出到一个结果文件，即获得整个处理结果。

在 MapReduce 整个过程可以概括为以下过程：
    输入 --> map --> shuffle --> reduce --> 输出
输入文件会被切分成多个块，每一块都有一个 map task

map 阶段的输出结果会先写到内存缓冲区，然后由缓冲区写到磁盘上。默认的缓冲区大小是 100M，溢出的百分比是 0.8，也就是说当缓冲区中达到 80M 的时候就会往磁盘上写。如果 map 计算完成后的中间结果没有达到 80M，最终也是要写到磁盘上的，因为它最终还是要形成文件。那么，在往磁盘上写的时候会进行分区和排序。一个 map 的输出可能有多个这个的文件，这些文件最终会合并成一个，这就是这个 map 的输出文件。

流程说明如下：

1、输入文件分片，每一片都由一个 MapTask 来处理
2、Map 输出的中间结果会先放在内存缓冲区中，这个缓冲区的大小默认是 100M，当缓冲区中的内容达到 80% 时（80M）会将缓冲区的内容写到磁盘上。也就是说，一个 map 会输出一个或者多个这样的文件，如果一个 map 输出的全部内容没有超过限制，那么最终也会发生这个写磁盘的操作，只不过是写几次的问题。
3、从缓冲区写到磁盘的时候，会进行分区并排序，分区指的是某个 key 应该进入到哪个分区，同一分区中的 key 会进行排序，如果定义了 Combiner 的话，也会进行 combine 操作
4、如果一个 map 产生的中间结果存放到多个文件，那么这些文件最终会合并成一个文件，这个合并过程不会改变分区数量，只会减少文件数量。例如，假设分了 3 个区，4 个文件，那么最终会合并成 1 个文件，3 个区
5、以上只是一个 map 的输出，接下来进入 reduce 阶段
6、每个 reducer 对应一个 ReduceTask，在真正开始 reduce 之前，先要从分区中抓取数据
7、相同的分区的数据会进入同一个 reduce。这一步中会从所有 map 输出中抓取某一分区的数据，在抓取的过程中伴随着排序、合并。
8、reduce 输出


### 快排、二分算法、链表、翻转二叉树

## 飞速过掉剑指 + SQL


### 哈希表的原理
key-value
哈希表是链表和数组的优点集合

<！-- ## B + 树、红黑树 -->

<！-- ## B + 树如何提高检索效率？（数据存放在叶子节点，和 B 树做对比） -->

<！-- ### 数据库如何提高检索效率 -->
<！-- 索引 + 缓存 -->

## UDF HDFS

## 抖音推荐算法